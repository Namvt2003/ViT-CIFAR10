# ViT-CIFAR10
This is a notebook for Vision Transformer that trained on the CIFAR-10 dataset from scratch.
With the Encoder based on : https://nlp.seas.harvard.edu/2018/04/03/attention.html
# Model Settings:
d_model = 384
d_ff = d_model * 4
heads = 8
labels = 10
dropout = 0.1
With 2 encoder layers.
Thank you for your attentions :))


![image](https://github.com/user-attachments/assets/00e3165e-bbb9-4db4-91fd-ee1eb513a4ee)




